# üöÄ Desafio #1 - Modelagem e Processamento de Dados  

Com os dados disponibilizados, foi constru√≠da uma modelagem de pipeline de acordo com o **conceito de camadas Medallion (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold)**.  
A solu√ß√£o considera um cen√°rio real de rotina em uma **Fintech**, onde grandes volumes de dados precisam ser processados diariamente com **qualidade, escalabilidade e governan√ßa**.  

## üìÇ Fontes de Dados  
- **core_pix** (CSV)  
- **core_account** (CSV)  
- **customer** (CSV)  

## ‚öôÔ∏è Desenvolvimento da Atividade
Esses arquivos foram ingeridos uilizando **Python** (pasta code do projeto) e versionados via **GitHub**. Ap√≥s a ingest√£o, eles foram escritos em uma inst√¢ncia do **PostgreSQL** rodando no **Docker** ('docker-compose up' para inciar e 'docker-compose down' para desligar a inst√¢ncia). A partir da camada **raw** realizei as transforma√ß√µes via **queries SQL** para as camadas **bronze**, **silver** e **gold** (pasta sql do projeto).

## üèóÔ∏è Arquitetura da Solu√ß√£o  
![alt text](image.png)

## üîÑ Camadas de Processamento  

### üî¥ Raw Layer  
- Ingest√£o dos arquivos **CSV** em um **Data Lake**.
- No desenho, a t√≠tulo de exemplo, utilizei o **AWS S3**. Para realizar a ingest√£o e consultas utilizei o **PostgreSQL** rodando no **Docker**.  
- Ingest√£o dos arquivos sem transforma√ß√£o.
- C√≥digos utilizados est√£o presentes na pasta **'code'**.  

### ü•â Bronze Layer  
- Cria√ß√£o das tabelas da camada **bronze**: `core_account`, `core_pix` e `customer`.  
- Os dados foram **copiados da camada raw** e sofreram algumas transforma√ß√µes como **convers√£o de tipos** e **renomea√ß√£o de colunas**:  
- O objetivo era criar a camada bronze com dados brutos padronizados, prontos para transforma√ß√µes posteriores.
- C√≥digo utilizado presente no arquivo **'bronze_layer.sql'**.

### ü•à Silver Layer  
- Cria√ß√£o das tabelas `core_account`, `core_pix` e `customer` com chaves prim√°rias.  
- Deduplica√ß√£o dos registros.  
- Consolida√ß√£o dos dados da Bronze garantindo unicidade por chave de neg√≥cio.
- C√≥digo utilizado presente no arquivo **'silver_layer.sql'**.  

### ü•á Gold Layer  
- Constru√ß√£o de **m√©tricas e cubos anal√≠ticos**.  
- Exemplo: volume transacionado via PIX por cliente, n√∫mero de aberturas de novas contas no m√™s etc.  
- Dados prontos para **BI (Power BI)**, **Data Science (Python)** e **Machine Learning/AI**.
- C√≥digo utilizado presente no arquivo **'gold_layer.sql'**.  


## ‚öôÔ∏è Orquestra√ß√£o e Processamento  
- **Apache Airflow** para orquestra√ß√£o dos pipelines a serem executados.  
- **dbt** para modelagem SQL no data warehouse (Bronze ‚Üí Silver ‚Üí Gold) e atualiza√ß√£o incremental dos dados.  


## ‚úÖ Data Quality & Observabilidade  
- Uso de **Soda** para monitorar:  
  - **Completude** (colunas n√£o nulas).  
  - **Unicidade** (IDs √∫nicos).  
  - **Conformidade** (tipos e formatos corretos).  
  - **Freshness** (atualiza√ß√£o dos dados).  

## üîê Governan√ßa e Seguran√ßa  
- Controle de acessos por **camada (RBAC)** presente nos schemas do DW.  
- Dados sens√≠veis **tokenizados e mascarados**.
- Logs de auditoria habilitados no **BigQuery**.  

## üìä Exemplos de M√©tricas (Camada Gold)
- Total de transa√ß√µes PIX por m√™s.  
- Valor m√©dio de transa√ß√µes por m√™s.  
- Novos clientes ativos por m√™s.
- Etc.

# üöÄ Desafio #2 - Visibilidade e Tratamento de Inconsist√™ncias no PIX  
Com os dados disponibilizados, optei por fazer 4 tipos de an√°lises que servir√£o para **valida√ß√£o** do fluxo, **report de problemas** e **inconsist√™ncias detectadas** no processo.

![alt text](image-2.png)

- **Transa√ß√µes n√£o registradas no servi√ßo core account** que est√£o presentes no servi√ßo core pix (core_account.id_transaction is null).
- **Transa√ß√µes n√£o registradas no servi√ßo core pix** que est√£o presentes no servi√ßo core account (core_pix.id_transaction is null).
- **Transa√ß√µes com valores divergentes** entre os servi√ßos core account e core pix visto que os valores transacionados devem ser o mesmo dentro das duas etapas.
- **Transa√ß√µes com datas de transa√ß√£o divergentes** entre os servi√ßos core account e core pix visto que o servi√ßo deve ser instant√¢neo.

As consultas utilizadas est√£o no arquivo **'inconsistencia_pix.sql'**.

# üöÄ Desafio #3 - API Pesquisa de Satisfa√ß√£o com Parceiro
A partir do cen√°rio apresentado, a solu√ß√£o pensada pode ser observada no esquema exemplificado abaixo:

![alt text](image-3.png)

**Roadmap de Desenvolvimento**:

1) **Sele√ß√£o de clientes** (aleatoriamente) que utilizaram o pix no √∫ltimo m√™s via consulta SQL na camada silver do nosso banco de dados. 
2) Utilizando um ambiente Python e um conector com o banco, vamos rodar a consulta, gerar um dataframe e, a partir disso, transformarmos os dados desse df em um **JSON que ser√° enviado para o sistema do fornecedor via API** utilizando o m√©todo POST da biblioteca requests.
3) O fornecedor, ap√≥s constatar o recebimento dos dados, ser√° respons√°vel por rodar a **pesquisa de satisfa√ß√£o**. 
4) Depois disso, ser√° gerado um novo script python para **leitura dos dados via API** com o sistema do fornecedor utilizando o m√©todo GET da biblioteca requests. **Os dados lidos ser√£o ingeridos na camada raw** no nosso data lake.
5) Cria√ß√£o e **transforma√ß√£o nas camadas bronze, silver e gold** dos dados da pesquisa.
6) **Desenvolvimento de m√©tricas**, visualiza√ß√µes, an√°lises, dashboards + **valida√ß√£o dos produtos** gerados a partir da camada gold.
7) Entegra final do produto **Pesquisa de Satisfa√ß√£o Clientes PIX**.

**Pontos Importantes**:

- Utilizaremos metodologias √°geis para o desenvolvimento, pensando a dura√ß√£o da *sprint* segundo o *cycle time* do time respons√°vel pelo desenvolvimento. Cada etapa do roadmap ser√° quebrada dentro da *sprint* e ao final de cada *sprint* ser√° feita a *review* da *sprint* para an√°lise do andamento do projeto.
- Podemos pensar um template para comunica√ß√£o com os steakholders sobre o andamento do projeto, seja um e-mail, uma apresenta√ß√£o ou uma mensagem no canal de comunica√ß√£o oficial da empresa.

